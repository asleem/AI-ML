{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ead3a6a-d25e-492c-b3c1-b612f63611e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.47.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee21228a-a825-4b13-8917-c3204ff4a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "# Choose a pre-trained BERT model for question answering\n",
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create a question-answering pipeline\n",
    "qa_pipeline = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Define a context and a question\n",
    "context = \"Large Language Models (LLMs) are deep learning algorithms capable of performing various natural language processing tasks. They are trained on massive datasets, enabling them to recognize, translate, predict, and generate text or other content. \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a156033-b95f-46a4-bac0-7c5fb0e44812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is LLM?\n",
      "Answer: Large Language Models\n"
     ]
    }
   ],
   "source": [
    "question = \"What is LLM?\"\n",
    "\n",
    "# Get the answer\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749860bc-1445-4f61-86ea-9b6d5639e4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Define Large Language Models?\n",
      "Answer: deep learning algorithms capable of performing various natural language processing tasks\n"
     ]
    }
   ],
   "source": [
    "question = \"Define Large Language Models?\"\n",
    "\n",
    "# Get the answer\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d715686f-385b-489c-8cb3-f20ff4372e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Why do we use LLM?\n",
      "Answer: to recognize, translate, predict, and generate text or other content\n"
     ]
    }
   ],
   "source": [
    "question = \"Why do we use LLM?\"\n",
    "\n",
    "# Get the answer\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3b6bbc9-d86f-4643-835f-21a8c002eec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: how LLM are created?\n",
      "Answer: trained on massive datasets\n"
     ]
    }
   ],
   "source": [
    "question = \"how LLM are created?\"\n",
    "\n",
    "# Get the answer\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9fc64e-6d57-4912-826d-dc9a95cdf5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
